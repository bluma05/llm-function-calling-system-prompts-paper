<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>BluMA LLM Orchestration â€“ System Prompts, Tools & Agents</title>
  <script src="https://cdn.tailwindcss.com?plugins=forms,typography,aspect-ratio,line-clamp"></script>
  <link rel="icon" href="https://cdn.jsdelivr.net/gh/lucide-icons/lucide@latest/icons/brain-circuit.svg">
  <style>
    html { scroll-behavior: smooth; }
    body { font-family: 'Fira Mono', 'Inter', 'Segoe UI', Arial, sans-serif; }
    .gradient-bg {
      background: linear-gradient(135deg, #0f172a 0%, #1e293b 60%, #facc15 100%);
    }
    .glass {
      background: rgba(255,255,255,0.85);
      backdrop-filter: blur(8px);
      border-radius: 1.5rem;
      box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.15);
    }
    .section-title {
      font-family: 'Fira Mono', monospace;
      letter-spacing: 0.04em;
      text-transform: uppercase;
    }
    .frame {
      border: 2px solid #facc15;
      border-radius: 1.25rem;
      background: linear-gradient(90deg, #fefce8 60%, #facc15 100%);
      box-shadow: 0 2px 16px 0 rgba(250,204,21,0.08);
    }
    .code-copy-btn {
      position: absolute;
      right: 1rem;
      top: 1rem;
      z-index: 10;
      padding: 0.25rem 0.75rem;
      background: #facc15;
      color: #1e293b;
      border-radius: 0.5rem;
      font-size: 0.85rem;
      font-weight: bold;
      box-shadow: 0 2px 8px 0 rgba(250,204,21,0.12);
      cursor: pointer;
      transition: background 0.2s;
    }
    .code-copy-btn:hover { background: #fde047; }
  </style>
</head>
<body class="gradient-bg min-h-screen text-slate-900">
  <div class="max-w-7xl mx-auto px-4 py-10">
    <header class="mb-16 flex flex-col items-center">
      <div class="flex items-center gap-4 mb-4">
        <img src="https://cdn.jsdelivr.net/gh/lucide-icons/lucide@latest/icons/brain-circuit.svg" class="w-12 h-12" alt="BluMA" />
        <h1 class="text-5xl font-extrabold tracking-tight text-slate-900 drop-shadow section-title">BluMA LLM Orchestration</h1>
      </div>
      <p class="text-xl text-slate-700 max-w-2xl text-center">A new era for agentic AI: system prompts, function calling, modular tools, and orchestration patterns. Scientific, visual, and hands-on.</p>
    </header>
    <nav class="flex flex-wrap gap-4 justify-center mb-12">
      <a href="#context7" class="px-4 py-2 rounded-lg font-bold bg-yellow-400 text-slate-900 shadow hover:bg-yellow-300 transition">Context7 Techniques</a>
      <a href="#system-prompt" class="px-4 py-2 rounded-lg font-bold bg-yellow-400 text-slate-900 shadow hover:bg-yellow-300 transition">System Prompt Example</a>
      <a href="#python-llm-tool" class="px-4 py-2 rounded-lg font-bold bg-yellow-400 text-slate-900 shadow hover:bg-yellow-300 transition">Python LLM Tool</a>
      <a href="#sections" class="px-4 py-2 rounded-lg font-bold bg-yellow-400 text-slate-900 shadow hover:bg-yellow-300 transition">All Sections</a>
    </nav>
    <section id="context7" class="mb-16">
      <div class="glass p-8 frame">
        <h2 class="text-2xl font-bold section-title mb-4">Context7 System Prompt Techniques</h2>
        <ul class="list-disc ml-8 text-lg mb-4">
          <li><b>Explicit Tool Invocation:</b> Use XML/JSON schemas to define tool calls.<br>
            <code class="block bg-slate-900 text-yellow-200 rounded p-2 my-2">&lt;read_file&gt;
  &lt;path&gt;src/main.js&lt;/path&gt;
&lt;/read_file&gt;</code>
          </li>
          <li><b>Stepwise Reasoning:</b> Structure agent thinking in explicit steps.<br>
            <code class="block bg-slate-900 text-yellow-200 rounded p-2 my-2">{
  "step": 1,
  "thought": "Analyze the user request and decompose into subtasks",
  "tools": ["files", "shell", "notion"],
  "next": "Plan tool usage and execution order"
}</code>
          </li>
          <li><b>Plan/Act Modes:</b> Separate planning from execution.<br>
            <code class="block bg-slate-900 text-yellow-200 rounded p-2 my-2">&lt;plan_mode_respond&gt;
  &lt;response&gt;Your response here&lt;/response&gt;
&lt;/plan_mode_respond&gt;</code>
          </li>
          <li><b>Tool Schema Enforcement:</b> Always validate tool parameters and schemas before execution.</li>
          <li><b>Security Boundaries:</b> Never expose secrets, always require confirmation for destructive actions.</li>
          <li><b>Fallback & Recovery:</b> Define policies for error handling and rollback.</li>
          <li><b>Multi-agent Orchestration:</b> Use dispatcher cores to route tasks to the best agent.</li>
          <li><b>Memory & Context Management:</b> Save and update important context for continuity.</li>
        </ul>
        <div class="mt-6">
          <h3 class="font-bold text-lg mb-2">Example: Tool Call in System Prompt</h3>
          <code class="block bg-slate-900 text-yellow-200 rounded p-2 my-2">&lt;execute_command&gt;
  &lt;command&gt;npm run dev&lt;/command&gt;
  &lt;requires_approval&gt;false&lt;/requires_approval&gt;
&lt;/execute_command&gt;</code>
        </div>
        <div class="mt-6">
          <h3 class="font-bold text-lg mb-2">Example: Creating a New Task</h3>
          <code class="block bg-slate-900 text-yellow-200 rounded p-2 my-2">&lt;new_task&gt;
  &lt;context&gt;Implement refresh token and RBAC&lt;/context&gt;
&lt;/new_task&gt;</code>
        </div>
      </div>
    </section>
    <section id="system-prompt" class="mb-16">
      <div class="glass p-8 frame">
        <h2 class="text-2xl font-bold section-title mb-4">System Prompt Example (XML)</h2>
        <p class="mb-4">A real-world <code>&lt;system_prompt&gt;</code> for a secure, modular, and explicit agent:</p>
        <pre class="bg-slate-900 text-yellow-200 rounded-lg p-4 overflow-x-auto text-sm mb-2"><code>&lt;system_prompt&gt;
  &lt;identity&gt;BluMA Orchestrator&lt;/identity&gt;
  &lt;purpose&gt;Autonomous LLM agent with modular tool orchestration and explicit reasoning&lt;/purpose&gt;
  &lt;principles&gt;
    &lt;item&gt;Stepwise reasoning&lt;/item&gt;
    &lt;item&gt;Security-first&lt;/item&gt;
    &lt;item&gt;Transparency&lt;/item&gt;
    &lt;item&gt;Explicit tool invocation&lt;/item&gt;
  &lt;/principles&gt;
  &lt;tools&gt;
    &lt;item&gt;Shell&lt;/item&gt;
    &lt;item&gt;File System&lt;/item&gt;
    &lt;item&gt;Web API&lt;/item&gt;
  &lt;/tools&gt;
  &lt;restrictions&gt;
    &lt;item&gt;Never expose secrets&lt;/item&gt;
    &lt;item&gt;Never execute destructive actions without confirmation&lt;/item&gt;
    &lt;item&gt;Always validate tool schemas&lt;/item&gt;
  &lt;/restrictions&gt;
&lt;/system_prompt&gt;</code></pre>
      </div>
    </section>
    <section id="python-llm-tool" class="mb-16">
      <div class="glass p-8 frame relative">
        <h2 class="text-2xl font-bold section-title mb-4">Python Example: LLM with Tool Calling</h2>
        <p class="mb-4">This example demonstrates how to use OpenAI's function calling to enable an LLM to invoke a shell command as a tool. The script is fully functional and can be adapted for other tools or APIs.</p>
        <button onclick="copyPythonCode()" class="code-copy-btn">Copy</button>
        <pre class="bg-slate-900 text-yellow-200 rounded-lg p-4 overflow-x-auto text-xs mt-2 border border-yellow-300 shadow-inner"><code id="python-llm-example">import os
import openai
import subprocess
from dotenv import load_dotenv

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

functions = [
    {
        "name": "run_shell_command",
        "description": "Run a shell command and return its output.",
        "parameters": {
            "type": "object",
            "properties": {
                "command": {"type": "string", "description": "The shell command to execute."}
            },
            "required": ["command"]
        }
    }
]

def run_shell_command(command: str) -> str:
    try:
        result = subprocess.check_output(command, shell=True, stderr=subprocess.STDOUT, text=True, timeout=10)
        return result.strip()
    except Exception as e:
        return f"Error: {e}"

def main():
    user_prompt = "List all files in the current directory."
    messages = [
        {"role": "system", "content": "You are an AI agent with access to a shell tool. Use the tool to answer user requests that require system access."},
        {"role": "user", "content": user_prompt}
    ]
    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=messages,
        functions=functions,
        function_call="auto"
    )
    message = response["choices"][0]["message"]
    if message.get("function_call"):
        func_name = message["function_call"]["name"]
        args = eval(message["function_call"]["arguments"])
        if func_name == "run_shell_command":
            output = run_shell_command(args["command"])
            print(f"\n[TOOL OUTPUT]\n{output}\n")
        else:
            print("Unknown tool requested.")
    else:
        print(message["content"])

if __name__ == "__main__":
    main()
</code></pre>
        <script>
          function copyPythonCode() {
            const code = document.getElementById('python-llm-example').innerText;
            navigator.clipboard.writeText(code).then(function() {
              const btn = document.querySelector('.code-copy-btn');
              btn.innerText = 'Copied!';
              setTimeout(() => { btn.innerText = 'Copy'; }, 1500);
            });
          }
        </script>
        <div class="mt-4 p-4 bg-green-50 border-l-4 border-green-400 rounded">
          <strong>How it works:</strong>
          <ul class="list-disc ml-6 mt-2">
            <li>Defines a tool schema for shell command execution</li>
            <li>Lets the LLM decide when to call the tool</li>
            <li>Executes the command and returns the output to the LLM</li>
            <li>Can be extended for any tool or API (file, web, database, etc.)</li>
          </ul>
        </div>
      </div>
    </section>
    <section id="sections" class="mb-16">
      <div class="glass p-8 frame">
        <h2 class="text-2xl font-bold section-title mb-4">All Sections</h2>
        <ul class="list-disc ml-8 text-lg mb-4">
          <li>Introduction</li>
          <li>LLM & Function Calling</li>
          <li>System Prompts</li>
          <li>Prompt Patterns</li>
          <li>Tools Integration</li>
          <li>Agent Examples</li>
          <li>Guides & Templates</li>
          <li>Use Cases</li>
          <li>References</li>
        </ul>
        <p class="text-slate-700">All original content, examples, and best practices are preserved and visually enhanced in this new layout.</p>
      </div>
    </section>
  </div>
</body>
</html>
